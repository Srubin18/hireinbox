# HIREINBOX V3 Brain Audit Report

**Date:** January 2026
**Auditor:** RALPH (Relentless Autonomous Launch & Progress Handler)
**Status:** CRITICAL ISSUES FOUND

---

## Executive Summary

The V3 fine-tuned model (`ft:gpt-4o-mini-2024-07-18:personal:hireinbox-v3:CqlakGfJ`) was trained on 6,000 examples with **systematic data quality issues**. These issues cause the model to hallucinate candidate details.

---

## Issues Found

### Issue 1: Education Field Not Serialized
**Severity:** CRITICAL
**Affected:** 5,400/5,400 training examples (100%)

```
Current:  "Education: [object Object]"
Expected: "Education: BCom Accounting, University of Cape Town, 2019"
```

**Root Cause:** JavaScript object passed directly to string template instead of being serialized.

### Issue 2: Experience Always Zero
**Severity:** CRITICAL
**Affected:** 5,400/5,400 training examples (100%)

```
Current:  "Experience: 0 years"
Expected: "Experience: 5 years"
```

**Root Cause:** Experience calculation not performed or not passed to template.

### Issue 3: Current Role Not Extracted
**Severity:** CRITICAL
**Affected:** 5,400/5,400 training examples (100%)

```
Current:  "Current Role: Not specified at Not specified"
Expected: "Current Role: Senior Accountant at Deloitte"
```

**Root Cause:** Role extraction logic failing silently.

### Issue 4: Work History Empty
**Severity:** HIGH
**Affected:** Most training examples

```
Current:  "WORK HISTORY:\n\n"
Expected: "WORK HISTORY:\n- Senior Accountant, Deloitte (2019-2023)\n- Junior Accountant, PwC (2017-2019)"
```

**Root Cause:** Work history array not being formatted.

---

## Impact Analysis

### What This Means

1. **Hallucination Risk:** The model learned to invent candidate details because training examples had empty CVs but detailed responses.

2. **Evidence Fabrication:** When the model says "5 years of experience in procurement" - this wasn't in the CV, it was hallucinated.

3. **False Confidence:** Model appears accurate but is making things up.

### Why It Still "Works"

The model produces plausible-sounding outputs because:
- The system prompt is strong
- SA context is baked in
- It learned the output format correctly
- It learned to sound confident

But the core skill (evidence-based analysis) was not properly trained.

---

## Recommendations

### Immediate (V3 Patch)
1. Update production code to validate evidence quotes exist in source CV
2. Add "not mentioned in CV" fallback logic
3. Log cases where AI claims facts not in source

### Short-Term (V4 Training)
1. Fix data generation pipeline to properly serialize CV content
2. Regenerate 10,000+ examples with real CV content
3. Add anti-hallucination examples:
   - When CV is sparse, response acknowledges gaps
   - Evidence quotes must exist in source
   - "Not mentioned" is valid response
4. Train V4 model

### Long-Term (V5+)
1. Collect real screening examples from production
2. Human-validated training data
3. Continuous learning from corrections

---

## Files to Fix

| File | Issue | Fix Required |
|------|-------|--------------|
| `generate-cvs.ts` | Education not serialized | Format education object to string |
| `generate-cvs.ts` | Experience not calculated | Calculate from work history dates |
| `run-screening.ts` | Work history not formatted | Format array to string |
| `format-finetune.mjs` | Data not validated | Add validation step |

---

## V4 Training Data Requirements

### Quality Criteria
- [ ] Education properly formatted (degree, institution, year)
- [ ] Experience calculated from work history
- [ ] Current role extracted from most recent position
- [ ] Work history formatted with dates and descriptions
- [ ] Skills list properly formatted
- [ ] No `[object Object]` anywhere
- [ ] Evidence quotes match source CV content

### Anti-Hallucination Examples (500 minimum)
- CV with minimal info → Response acknowledges gaps
- CV with missing skills → Response says "not mentioned"
- CV with no experience → Response correctly identifies entry-level
- Sparse CV → Lower confidence, more "unable to verify" statements

### Target Dataset
- 15,000 clean examples (up from 6,000)
- 30% SHORTLIST, 40% CONSIDER, 30% REJECT
- 500+ anti-hallucination examples
- 200+ SA-specific edge cases

---

## Conclusion

**V3 Brain Status:** Functional but flawed. Suitable for demo/pilot with human oversight.

**V4 Priority:** HIGH. Fix data pipeline before scaling to 100 customers.

**Risk Mitigation:** Add runtime validation to catch hallucinated evidence.

---

*Report generated by RALPH - January 2026*
